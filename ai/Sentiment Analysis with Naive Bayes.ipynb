{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with Naive Bayes on IMDB review dataset\n",
    "\n",
    "In this lab, you will work on the dataset of movie reviews provided by IMDB on the [Stanford Page](http://ai.stanford.edu/Ã£maas/data/sentiment/aclimdb.tar.gz).\n",
    "\n",
    "Start by unpacking the data in the command line:\n",
    "\n",
    "```\n",
    "tar -xvf filename.tar.gz\n",
    "```\n",
    "\n",
    "The goal is, given a set of positive and negative reviews, train a classifier able to predict, for any given new review, if it is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import glob\n",
    "import debug_utils\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Load the data\n",
    "\n",
    "- Can you write a function that loads the data, and returns a tuple of lists: the first list is a list of strings (the reviews themselves) and the second is the list of all the labels: 0 for bad and 1 for good ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(folder, cats):classifier\n",
    "    \"\"\"This function should return two list: the reviews and their label.\"\"\"\n",
    "    # Implement it here !!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = \"<put your folder here>\"\n",
    "classes = ['neg', 'pos']\n",
    "x_train, y_train = loadData(os.path.join(data_folder, 'train'), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Train a Naive Bayes classifier\n",
    "\n",
    "- use sklearn.pipeline to create a pipeline that should:\n",
    "    - first make a bag-of-words transformation\n",
    "    - them use a classifier.\n",
    "- Can you visualize a bag-of-word ? What kind of object is it in python sklearn ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: test on some example\n",
    "\n",
    "- Implement the showPrediction function that will show the prediction of any text given as input\n",
    "- Can you find ways to fool your classifier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPrediction(text: str):\n",
    "    \"\"\"This should show if the text is classified as good or bad.\"\"\"\n",
    "    # Implement this !\n",
    "    pass\n",
    "\n",
    "showPrediction('This movie is pure bullshit, worse ever made in the history of the universe. shame on you.')\n",
    "showPrediction('Best movie ever')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Evaluation\n",
    "\n",
    "- Compute the performance on the test set: what is the average accuracy ?\n",
    "- use sklearn.metrics to show the classification report on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement this here !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: TF-IDF Feature\n",
    "\n",
    "- In information retrieval, the TF-IDF is used for better description of document. Can you modify your pipeline to make it use it ? Does it change much the output ?\n",
    "- Can you change the NaiveBayes classifier for another one ? Any improvement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Bias in the training set\n",
    "\n",
    "The data set we have used is well balanced: 50% of positive examples and 50% of negative ones. At least it seems to be, because we do not know what is the prior of positive and negative reviews on IMDB... or outside. So even the notion of balance is fuzzy, since we cannot know what is the real proportion.\n",
    "\n",
    "But we can still observe that this is critical when training a classifier. The bias in the training set impacts the performance of the classifier on real world data, which is where you want your classifier to run.\n",
    "\n",
    "- Train your Naive Bayes classifier on the imbalanced data and evaluate it again the same test set as before. What do you observe ?\n",
    "- Is there a way to change the parameters of the NaiveBayes classifier to take the biased data into account ? Do it make a big difference ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance(x, y, p):\n",
    "    \"\"\"Assuming that the training set is made of two classes, in order, make the second\n",
    "    class become only a fraction p of the trainig set.\"\"\"\n",
    "    n = int((0.5 + p) * len(x))\n",
    "    return x[:n], y[:n]\n",
    "\n",
    "x_train_bias, y_train_bias = imbalance(x_train, y_train, 0.20)\n",
    "\n",
    "# Write the code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
